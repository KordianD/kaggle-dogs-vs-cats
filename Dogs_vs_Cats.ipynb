{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We would be using Keras with Tensorflow background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, ZeroPadding2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sizes of the scaled images\n",
    "height = 256\n",
    "width = 256\n",
    "\n",
    "# Path to subfolders\n",
    "train_path = 'train'\n",
    "validation_path = 'validation'\n",
    "\n",
    "# Number of training example (10k cats + 10k dogs in train directory)\n",
    "train_samples = 20000\n",
    "validation_samples = 5000\n",
    "\n",
    "# Number of epochs\n",
    "ep = 5\n",
    "\n",
    "batch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(\n",
    "    rescale=1 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "train_generator = train_data.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(width, height),\n",
    "    batch_size=batch,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(width, height),\n",
    "    batch_size=batch,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will be using ZeroPadding to ensure that after convolution sizes will stay the same\n",
    "# 'Glorot_uniform' - its Xavier initializer, to more sensible way to initialize weights rather than entirely randomly\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(width, height, 3), kernel_initializer='glorot_uniform', padding='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "          \n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer='glorot_uniform'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "          \n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer='glorot_uniform'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "          \n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer='glorot_uniform'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "          \n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer='glorot_uniform'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "          \n",
    "model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer='glorot_uniform'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "          \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, kernel_initializer='glorot_uniform'))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 2434s - loss: 0.6937 - acc: 0.5948 - val_loss: 0.6060 - val_acc: 0.6560\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 2408s - loss: 0.5762 - acc: 0.6912 - val_loss: 0.9063 - val_acc: 0.6503\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 2404s - loss: 0.4620 - acc: 0.7772 - val_loss: 0.4078 - val_acc: 0.8068\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 2404s - loss: 0.3843 - acc: 0.8243 - val_loss: 0.3600 - val_acc: 0.8413\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 2406s - loss: 0.3297 - acc: 0.8544 - val_loss: 0.3321 - val_acc: 0.8495\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_samples // batch,\n",
    "    epochs=ep,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_samples // batch)\n",
    "\n",
    "model.save_weights('first_try.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = 84.95 # on validation set\n",
    "results = 85.44 # on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('first.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
